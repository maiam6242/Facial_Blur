{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facial_Blur.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maiam6242/Facial_Blur/blob/master/Facial_Blur.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qag1NL_FWy88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hey! this is wacky!!\n",
        "# can you see this?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t20OdGNZI7l",
        "colab_type": "text"
      },
      "source": [
        "yooo can you see me writing this?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4x1Y1xtZMAi",
        "colab_type": "code",
        "outputId": "a304b80c-082c-4842-d3a0-771ac4fb2548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "!pip install torchviz\n",
        "# !CUDA_LAUNCH_BLOCKING=1\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.autograd import Variable\n",
        "from torchviz import make_dot\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np # we always love numpy\n",
        "import time\n",
        "import gdown\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "gdown.download('https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/The%20Eiffel%20Tower.npy', 'eiffeltower.npy', False)\n",
        "gdown.download('https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bear.npy', 'bear.npy', False)\n",
        "gdown.download('https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy', 'airplane.npy', False)\n",
        "gdown.download('https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broccoli.npy', 'broccoli.npy', False)\n",
        "gdown.download('https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dog.npy', 'dog.npy', False)\n",
        "gdown.download('https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy', 'broom.npy', False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.16.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/The%20Eiffel%20Tower.npy\n",
            "To: /content/eiffeltower.npy\n",
            "100%|██████████| 106M/106M [00:00<00:00, 238MB/s] \n",
            "Downloading...\n",
            "From: https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bear.npy\n",
            "To: /content/bear.npy\n",
            "100%|██████████| 106M/106M [00:00<00:00, 222MB/s] \n",
            "Downloading...\n",
            "From: https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
            "To: /content/airplane.npy\n",
            "100%|██████████| 119M/119M [00:00<00:00, 222MB/s]\n",
            "Downloading...\n",
            "From: https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broccoli.npy\n",
            "To: /content/broccoli.npy\n",
            "100%|██████████| 104M/104M [00:00<00:00, 207MB/s] \n",
            "Downloading...\n",
            "From: https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dog.npy\n",
            "To: /content/dog.npy\n",
            "100%|██████████| 119M/119M [00:00<00:00, 173MB/s]\n",
            "Downloading...\n",
            "From: https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy\n",
            "To: /content/broom.npy\n",
            "100%|██████████| 91.7M/91.7M [00:00<00:00, 191MB/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'broom.npy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqPERGQfVgc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tower = np.load('eiffeltower.npy') #type = 1\n",
        "bear = np.load('bear.npy') # type = 0\n",
        "airplane = np.load('airplane.npy')\n",
        "broccoli = np.load('broccoli.npy')\n",
        "dog = np.load('dog.npy')\n",
        "broom = np.load('broom.npy')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICO8bUo6V2He",
        "colab_type": "code",
        "outputId": "f0b936ff-c318-4629-b9a4-e83adc6362af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "X = airplane[750]\n",
        "X = np.resize(X,(28,28))\n",
        "X = np.invert(X)\n",
        "plt.imshow(X, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnoRPCJ8wWgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7yhVEn8Ql_h",
        "colab_type": "code",
        "outputId": "038376d7-87ef-4a05-b464-9d66c084ddbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "import torch\n",
        "\n",
        "# class QuickDrawData(Dataset):\n",
        "#     def __init__(self, tower, bear, airplane, broccoli):\n",
        "#         super(QuickDrawData, self).__init__()\n",
        "#         self.data = np.vstack((tower, bear, airplane, broccoli))\n",
        "#         self.targets = np.concatenate((0*np.ones(tower.shape[0]), 1*np.ones(bear.shape[0]), 2*np.ones(airplane.shape[0]), 3*np.ones(broccoli.shape[0])))\n",
        "#         print(len(self.data))\n",
        "#         self.classes = ['tower', 'bear', 'airplane', 'broccoli']\n",
        "    \n",
        "#     def __len__(self):\n",
        "#         return self.targets.shape[0]\n",
        "    \n",
        "#     def __getitem__(self, index):\n",
        "#         return torch.FloatTensor(self.data[index, :].reshape((28, 28))).unsqueeze(0), int(self.targets[index])\n",
        "class QuickDrawData(Dataset):\n",
        "    def __init__(self, *args):\n",
        "        super(QuickDrawData, self).__init__()\n",
        "        count = 0\n",
        "        # self.data = np.empty(args[0].shape, dtype=int)\n",
        "        # self.targets = np.empty(args[0].shape, dtype=int)\n",
        "        self.classes = []\n",
        "        for arg in args:\n",
        "          # print(str(arg))\n",
        "          if type(arg) == str:\n",
        "            self.classes += arg\n",
        "          else:\n",
        "\n",
        "            if count == 0:\n",
        "              print(arg.shape)\n",
        "              self.data = np.array(arg)\n",
        "              self.targets = np.array(0*np.ones(arg.shape[0], dtype = int))\n",
        "              print(self.targets)\n",
        "              print(type(self.targets))\n",
        "              print(type(self.data))\n",
        "              print(type(self.classes))\n",
        "            else:\n",
        "              self.data = np.vstack((self.data, arg))\n",
        "              print(int(count)*np.ones(arg.shape[0], dtype = int))\n",
        "              print(self.targets)\n",
        "              self.targets = np.hstack((self.targets, int(count)*np.ones(arg.shape[0], dtype = int)))\n",
        "            count+=1\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.targets.shape[0]\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return torch.FloatTensor(self.data[index, :].reshape((28, 28))).unsqueeze(0), int(self.targets[index])\n",
        "\n",
        "quick_draw_data = QuickDrawData(tower, bear, airplane, broccoli, dog, broom, 'tower', 'bear', 'airplane', 'brocolli', 'dog', 'broom')\n",
        "\n",
        "im, target = quick_draw_data[55102]\n",
        "plt.imshow(im.squeeze(), cmap='gray')\n",
        "plt.show()\n",
        "im.shape\n",
        "print(target)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(134801, 784)\n",
            "[0 0 0 ... 0 0 0]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "[1 1 1 ... 1 1 1]\n",
            "[0 0 0 ... 0 0 0]\n",
            "[2 2 2 ... 2 2 2]\n",
            "[0 0 0 ... 1 1 1]\n",
            "[3 3 3 ... 3 3 3]\n",
            "[0 0 0 ... 2 2 2]\n",
            "[4 4 4 ... 4 4 4]\n",
            "[0 0 0 ... 3 3 3]\n",
            "[5 5 5 ... 5 5 5]\n",
            "[0 0 0 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nICjCDwRF+IGgCD8QFOEHgiL8QFD/B8Pzhyim7SBFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi8X_pFZAcm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9fMDbMQBAdAc",
        "colab": {}
      },
      "source": [
        "# from torch.utils.data import Dataset\n",
        "# from torch.utils.data import random_split\n",
        "\n",
        "# import torch\n",
        "\n",
        "# class QuickDrawData(Dataset):\n",
        "#     def __init__(self,airplane, broccoli):\n",
        "#         super(QuickDrawData, self).__init__()\n",
        "#         self.data = np.vstack((airplane, broccoli))\n",
        "#         self.targets = np.concatenate((0*np.ones(airplane.shape[0]), 1*np.ones(broccoli.shape[0])))\n",
        "#         print(len(self.data))\n",
        "#         # self.classes = ['tower', 'bear', 'airplane', 'broccoli']\n",
        "#         self.classes = ['airplane', 'broccoli']\n",
        "    \n",
        "#     def __len__(self):\n",
        "#         return self.targets.shape[0]\n",
        "    \n",
        "#     def __getitem__(self, index):\n",
        "#         return torch.FloatTensor(self.data[index, :].reshape((28, 28))).unsqueeze(0), int(self.targets[index])\n",
        "\n",
        "# quick_draw_data = QuickDrawData(airplane, broccoli)\n",
        "\n",
        "# im, target = quick_draw_data[502]\n",
        "# plt.imshow(im.squeeze(), cmap='gray')\n",
        "# plt.show()\n",
        "# im.shape\n",
        "# print(target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbaebNQ7RwG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = int(len(quick_draw_data)*.9)\n",
        "train, test = random_split(quick_draw_data, [x,(len(quick_draw_data) - x)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMrsY0PERwJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data set information\n",
        "\n",
        "image_dims = 1, 28, 28\n",
        "n_training_samples = len(train) # How many training images to use\n",
        "n_test_samples = len(test) # How many test images to use\n",
        "classes = ('tower', 'bear', 'airplane', 'brocolli', 'dog', 'broom')\n",
        "\n",
        "# Load the training set\n",
        "train_set = train\n",
        "train_sampler = SubsetRandomSampler(\n",
        "    np.arange(n_training_samples, dtype=np.int64))\n",
        "\n",
        "#Load the test set\n",
        "test_set = test\n",
        "test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dv6-ImXRwMA",
        "colab_type": "code",
        "outputId": "826f8f58-da4e-4a34-ffd4-7f6421db291f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(test_set)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataset.Subset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QoJj27WRwO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyCNN(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(MyCNN, self).__init__()\n",
        "    \n",
        "    num_kernels = 16\n",
        "\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(1, num_kernels, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "    self.conv2 = nn.Conv2d(num_kernels, num_kernels*2, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "    self.maxpool_output_size1 = int(num_kernels*(image_dims[1]/2) * (image_dims[2]/2))\n",
        "    self.maxpool_output_size2 = int(num_kernels*(image_dims[1]/4) * (image_dims[2]/4)*2)\n",
        "\n",
        "    self.batchnorm1 = nn.BatchNorm2d(num_kernels)\n",
        "    self.batchnorm2 = nn.BatchNorm2d(num_kernels*2)\n",
        "    \n",
        "    \n",
        "    fcl_size = 256\n",
        "    fcl_size2 = 128\n",
        "    fcl_size3 = 64\n",
        "    self.fc1 = nn.Linear(1568, fcl_size)\n",
        "    self.activation_func = torch.nn.ReLU()\n",
        "    # fc2_size = fcl_size\n",
        "\n",
        "    self.fc2 = nn.Linear(fcl_size, fcl_size2)\n",
        "    self.fc4 = nn.Linear(fcl_size2, fcl_size3)\n",
        "    # self.fc7 = nn.Linear(fcl_size, fcl_size)\n",
        "\n",
        "    self.activation_func = torch.nn.ReLU()\n",
        "\n",
        "    fc3_size = len(classes)\n",
        "    # fc3_size = 6\n",
        "    self.fc3 = nn.Linear(fcl_size3, fc3_size)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "\n",
        "    x = self.activation_func(x)\n",
        "\n",
        "    x = self.batchnorm1(x)\n",
        "\n",
        "    x = self.pool1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "\n",
        "    x = self.activation_func(x)\n",
        "\n",
        "    x = self.batchnorm2(x)\n",
        "\n",
        "    x = self.pool2(x)\n",
        "\n",
        "    # x = self.pool1(x)\n",
        "    # x = self.activation_func(x)\n",
        "    # x = x.view(-1, self.maxpool_output_size1)\n",
        "    # x = self.pool2(x)\n",
        "    # x = self.activation_func(x)\n",
        "    x = self.activation_func(x)\n",
        "    x = x.view(-1, self.maxpool_output_size2)\n",
        "\n",
        "    # print(x.size())\n",
        "\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    x = self.activation_func(x)\n",
        "\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    x = self.activation_func(x)\n",
        "\n",
        "    x = self.fc4(x)\n",
        "\n",
        "    x = self.activation_func(x)\n",
        "    # x = self.fc2(x)\n",
        "    # x = self.activation_func(x)\n",
        "    x = self.fc3(x)\n",
        "    x = torch.nn.functional.log_softmax(x)\n",
        "    # x = self.activation_func(x)\n",
        "\n",
        "    # x = self.activation_func7(x)\n",
        "    return x\n",
        "\n",
        "  def get_loss(self, learning_rate):\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "    return loss, optimizer\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHaayoLKRwaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = MyCNN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SbsGk9qjpmY",
        "colab_type": "code",
        "outputId": "ccb63282-94cc-4aff-e64d-ef771de7a718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def visualize_network(net):\n",
        "    # Visualize the architecture of the model\n",
        "    # We need to give the net a fake input for this library to visualize the architecture\n",
        "    fake_input = Variable(torch.zeros((1, image_dims[0], image_dims[1], image_dims[2]))).to(device)\n",
        "    outputs = net(fake_input)\n",
        "    # Plot the DAG (Directed Acyclic Graph) of the model\n",
        "    return make_dot(outputs, dict(net.named_parameters()))\n",
        "\n",
        "# Define what device we want to use\n",
        "device = 'cuda' # 'cpu' if we want to not use the gpu\n",
        "# Initialize the model, loss, and optimization function\n",
        "net = MyCNN()\n",
        "# This tells our model to send all of the tensors and operations to the GPU (or keep them at the CPU if we're not using GPU)\n",
        "net.to(device)\n",
        "# \n",
        "visualize_network(net)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fb510ffff60>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"463pt\" height=\"864pt\"\n viewBox=\"0.00 0.00 463.04 864.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(.7135 .7135) rotate(0) translate(4 1207)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-1207 645,-1207 645,4 -4,4\"/>\n<!-- 140413872346784 -->\n<g id=\"node1\" class=\"node\">\n<title>140413872346784</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"539,-21 414,-21 414,0 539,0 539,-21\"/>\n<text text-anchor=\"middle\" x=\"476.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">LogSoftmaxBackward</text>\n</g>\n<!-- 140413872346392 -->\n<g id=\"node2\" class=\"node\">\n<title>140413872346392</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"528.5,-78 424.5,-78 424.5,-57 528.5,-57 528.5,-78\"/>\n<text text-anchor=\"middle\" x=\"476.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 140413872346392&#45;&gt;140413872346784 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140413872346392&#45;&gt;140413872346784</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M476.5,-56.7787C476.5,-49.6134 476.5,-39.9517 476.5,-31.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"480.0001,-31.1732 476.5,-21.1732 473.0001,-31.1732 480.0001,-31.1732\"/>\n</g>\n<!-- 140413872345776 -->\n<g id=\"node3\" class=\"node\">\n<title>140413872345776</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"411.5,-148 357.5,-148 357.5,-114 411.5,-114 411.5,-148\"/>\n<text text-anchor=\"middle\" x=\"384.5\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc3.bias</text>\n<text text-anchor=\"middle\" x=\"384.5\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (6)</text>\n</g>\n<!-- 140413872345776&#45;&gt;140413872346392 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140413872345776&#45;&gt;140413872346392</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M409.1543,-113.9832C422.6894,-104.641 439.3926,-93.1122 452.778,-83.8734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"454.7865,-86.7398 461.0283,-78.1788 450.8102,-80.9788 454.7865,-86.7398\"/>\n</g>\n<!-- 140413872346112 -->\n<g id=\"node4\" class=\"node\">\n<title>140413872346112</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"523.5,-141.5 429.5,-141.5 429.5,-120.5 523.5,-120.5 523.5,-141.5\"/>\n<text text-anchor=\"middle\" x=\"476.5\" y=\"-127.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140413872346112&#45;&gt;140413872346392 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140413872346112&#45;&gt;140413872346392</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M476.5,-120.2281C476.5,-111.5091 476.5,-98.9699 476.5,-88.3068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"480.0001,-88.1128 476.5,-78.1128 473.0001,-88.1129 480.0001,-88.1128\"/>\n</g>\n<!-- 140413872347680 -->\n<g id=\"node5\" class=\"node\">\n<title>140413872347680</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"527.5,-211.5 423.5,-211.5 423.5,-190.5 527.5,-190.5 527.5,-211.5\"/>\n<text text-anchor=\"middle\" x=\"475.5\" y=\"-197.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 140413872347680&#45;&gt;140413872346112 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140413872347680&#45;&gt;140413872346112</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M475.6519,-190.3685C475.7972,-180.1925 476.0206,-164.5606 476.2016,-151.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"479.7034,-151.7806 476.3467,-141.7315 472.7041,-151.6805 479.7034,-151.7806\"/>\n</g>\n<!-- 140413872348856 -->\n<g id=\"node6\" class=\"node\">\n<title>140413872348856</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"410.5,-288 356.5,-288 356.5,-254 410.5,-254 410.5,-288\"/>\n<text text-anchor=\"middle\" x=\"383.5\" y=\"-274.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc4.bias</text>\n<text text-anchor=\"middle\" x=\"383.5\" y=\"-261.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64)</text>\n</g>\n<!-- 140413872348856&#45;&gt;140413872347680 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140413872348856&#45;&gt;140413872347680</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M406.2416,-253.6966C420.6068,-242.7666 439.0787,-228.7119 453.3325,-217.8666\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"455.7491,-220.4258 461.5881,-211.5852 451.5104,-214.855 455.7491,-220.4258\"/>\n</g>\n<!-- 140413838250560 -->\n<g id=\"node7\" class=\"node\">\n<title>140413838250560</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"522.5,-281.5 428.5,-281.5 428.5,-260.5 522.5,-260.5 522.5,-281.5\"/>\n<text text-anchor=\"middle\" x=\"475.5\" y=\"-267.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140413838250560&#45;&gt;140413872347680 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140413838250560&#45;&gt;140413872347680</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M475.5,-260.3685C475.5,-250.1925 475.5,-234.5606 475.5,-221.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"479.0001,-221.7315 475.5,-211.7315 472.0001,-221.7316 479.0001,-221.7315\"/>\n</g>\n<!-- 140413838250392 -->\n<g id=\"node8\" class=\"node\">\n<title>140413838250392</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"527.5,-351.5 423.5,-351.5 423.5,-330.5 527.5,-330.5 527.5,-351.5\"/>\n<text text-anchor=\"middle\" x=\"475.5\" y=\"-337.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 140413838250392&#45;&gt;140413838250560 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140413838250392&#45;&gt;140413838250560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M475.5,-330.3685C475.5,-320.1925 475.5,-304.5606 475.5,-291.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"479.0001,-291.7315 475.5,-281.7315 472.0001,-291.7316 479.0001,-291.7315\"/>\n</g>\n<!-- 140413838250056 -->\n<g id=\"node9\" class=\"node\">\n<title>140413838250056</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"410.5,-428 356.5,-428 356.5,-394 410.5,-394 410.5,-428\"/>\n<text text-anchor=\"middle\" x=\"383.5\" y=\"-414.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc2.bias</text>\n<text text-anchor=\"middle\" x=\"383.5\" y=\"-401.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (128)</text>\n</g>\n<!-- 140413838250056&#45;&gt;140413838250392 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140413838250056&#45;&gt;140413838250392</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M406.2416,-393.6966C420.6068,-382.7666 439.0787,-368.7119 453.3325,-357.8666\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"455.7491,-360.4258 461.5881,-351.5852 451.5104,-354.855 455.7491,-360.4258\"/>\n</g>\n<!-- 140413838250168 -->\n<g id=\"node10\" class=\"node\">\n<title>140413838250168</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"522.5,-421.5 428.5,-421.5 428.5,-400.5 522.5,-400.5 522.5,-421.5\"/>\n<text text-anchor=\"middle\" x=\"475.5\" y=\"-407.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140413838250168&#45;&gt;140413838250392 -->\n<g id=\"edge9\" class=\"edge\">\n<title>140413838250168&#45;&gt;140413838250392</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M475.5,-400.3685C475.5,-390.1925 475.5,-374.5606 475.5,-361.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"479.0001,-361.7315 475.5,-351.7315 472.0001,-361.7316 479.0001,-361.7315\"/>\n</g>\n<!-- 140413838251344 -->\n<g id=\"node11\" class=\"node\">\n<title>140413838251344</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"526.5,-491.5 422.5,-491.5 422.5,-470.5 526.5,-470.5 526.5,-491.5\"/>\n<text text-anchor=\"middle\" x=\"474.5\" y=\"-477.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 140413838251344&#45;&gt;140413838250168 -->\n<g id=\"edge10\" class=\"edge\">\n<title>140413838251344&#45;&gt;140413838250168</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M474.6519,-470.3685C474.7972,-460.1925 475.0206,-444.5606 475.2016,-431.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"478.7034,-431.7806 475.3467,-421.7315 471.7041,-431.6805 478.7034,-431.7806\"/>\n</g>\n<!-- 140413838253360 -->\n<g id=\"node12\" class=\"node\">\n<title>140413838253360</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"410.5,-568 356.5,-568 356.5,-534 410.5,-534 410.5,-568\"/>\n<text text-anchor=\"middle\" x=\"383.5\" y=\"-554.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc1.bias</text>\n<text text-anchor=\"middle\" x=\"383.5\" y=\"-541.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256)</text>\n</g>\n<!-- 140413838253360&#45;&gt;140413838251344 -->\n<g id=\"edge11\" class=\"edge\">\n<title>140413838253360&#45;&gt;140413838251344</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M405.9944,-533.6966C420.2034,-522.7666 438.4745,-508.7119 452.5735,-497.8666\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"454.947,-500.4565 460.7393,-491.5852 450.679,-494.9081 454.947,-500.4565\"/>\n</g>\n<!-- 140413838252128 -->\n<g id=\"node13\" class=\"node\">\n<title>140413838252128</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"520,-561.5 429,-561.5 429,-540.5 520,-540.5 520,-561.5\"/>\n<text text-anchor=\"middle\" x=\"474.5\" y=\"-547.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ViewBackward</text>\n</g>\n<!-- 140413838252128&#45;&gt;140413838251344 -->\n<g id=\"edge12\" class=\"edge\">\n<title>140413838252128&#45;&gt;140413838251344</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M474.5,-540.3685C474.5,-530.1925 474.5,-514.5606 474.5,-501.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"478.0001,-501.7315 474.5,-491.7315 471.0001,-501.7316 478.0001,-501.7315\"/>\n</g>\n<!-- 140413838253696 -->\n<g id=\"node14\" class=\"node\">\n<title>140413838253696</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"520.5,-631.5 426.5,-631.5 426.5,-610.5 520.5,-610.5 520.5,-631.5\"/>\n<text text-anchor=\"middle\" x=\"473.5\" y=\"-617.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140413838253696&#45;&gt;140413838252128 -->\n<g id=\"edge13\" class=\"edge\">\n<title>140413838253696&#45;&gt;140413838252128</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M473.6519,-610.3685C473.7972,-600.1925 474.0206,-584.5606 474.2016,-571.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"477.7034,-571.7806 474.3467,-561.7315 470.7041,-571.6805 477.7034,-571.7806\"/>\n</g>\n<!-- 140413838253472 -->\n<g id=\"node15\" class=\"node\">\n<title>140413838253472</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"563.5,-695 383.5,-695 383.5,-674 563.5,-674 563.5,-695\"/>\n<text text-anchor=\"middle\" x=\"473.5\" y=\"-681.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MaxPool2DWithIndicesBackward</text>\n</g>\n<!-- 140413838253472&#45;&gt;140413838253696 -->\n<g id=\"edge14\" class=\"edge\">\n<title>140413838253472&#45;&gt;140413838253696</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M473.5,-673.7281C473.5,-665.0091 473.5,-652.4699 473.5,-641.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"477.0001,-641.6128 473.5,-631.6128 470.0001,-641.6129 477.0001,-641.6128\"/>\n</g>\n<!-- 140413837834224 -->\n<g id=\"node16\" class=\"node\">\n<title>140413837834224</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"550,-752 397,-752 397,-731 550,-731 550,-752\"/>\n<text text-anchor=\"middle\" x=\"473.5\" y=\"-738.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnBatchNormBackward</text>\n</g>\n<!-- 140413837834224&#45;&gt;140413838253472 -->\n<g id=\"edge15\" class=\"edge\">\n<title>140413837834224&#45;&gt;140413838253472</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M473.5,-730.7787C473.5,-723.6134 473.5,-713.9517 473.5,-705.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"477.0001,-705.1732 473.5,-695.1732 470.0001,-705.1732 477.0001,-705.1732\"/>\n</g>\n<!-- 140413837833888 -->\n<g id=\"node17\" class=\"node\">\n<title>140413837833888</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"401.5,-815.5 307.5,-815.5 307.5,-794.5 401.5,-794.5 401.5,-815.5\"/>\n<text text-anchor=\"middle\" x=\"354.5\" y=\"-801.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140413837833888&#45;&gt;140413837834224 -->\n<g id=\"edge16\" class=\"edge\">\n<title>140413837833888&#45;&gt;140413837834224</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M374.4179,-794.3715C393.553,-784.1608 422.6839,-768.6162 444.4131,-757.0212\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"446.3423,-759.9589 453.5171,-752.1631 443.0468,-753.7831 446.3423,-759.9589\"/>\n</g>\n<!-- 140413837835736 -->\n<g id=\"node18\" class=\"node\">\n<title>140413837835736</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"433,-879 276,-879 276,-858 433,-858 433,-879\"/>\n<text text-anchor=\"middle\" x=\"354.5\" y=\"-865.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n</g>\n<!-- 140413837835736&#45;&gt;140413837833888 -->\n<g id=\"edge17\" class=\"edge\">\n<title>140413837835736&#45;&gt;140413837833888</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M354.5,-857.7281C354.5,-849.0091 354.5,-836.4699 354.5,-825.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"358.0001,-825.6128 354.5,-815.6128 351.0001,-825.6129 358.0001,-825.6128\"/>\n</g>\n<!-- 140413837834504 -->\n<g id=\"node19\" class=\"node\">\n<title>140413837834504</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"295.5,-942.5 115.5,-942.5 115.5,-921.5 295.5,-921.5 295.5,-942.5\"/>\n<text text-anchor=\"middle\" x=\"205.5\" y=\"-928.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MaxPool2DWithIndicesBackward</text>\n</g>\n<!-- 140413837834504&#45;&gt;140413837835736 -->\n<g id=\"edge18\" class=\"edge\">\n<title>140413837834504&#45;&gt;140413837835736</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M230.4392,-921.3715C255.0429,-910.8861 292.8449,-894.7758 320.2558,-883.094\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"321.6522,-886.3036 329.4794,-879.1631 318.9077,-879.864 321.6522,-886.3036\"/>\n</g>\n<!-- 140413837832824 -->\n<g id=\"node20\" class=\"node\">\n<title>140413837832824</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"282,-1006 129,-1006 129,-985 282,-985 282,-1006\"/>\n<text text-anchor=\"middle\" x=\"205.5\" y=\"-992.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnBatchNormBackward</text>\n</g>\n<!-- 140413837832824&#45;&gt;140413837834504 -->\n<g id=\"edge19\" class=\"edge\">\n<title>140413837832824&#45;&gt;140413837834504</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M205.5,-984.7281C205.5,-976.0091 205.5,-963.4699 205.5,-952.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"209.0001,-952.6128 205.5,-942.6128 202.0001,-952.6129 209.0001,-952.6128\"/>\n</g>\n<!-- 140413837835792 -->\n<g id=\"node21\" class=\"node\">\n<title>140413837835792</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"133.5,-1069.5 39.5,-1069.5 39.5,-1048.5 133.5,-1048.5 133.5,-1069.5\"/>\n<text text-anchor=\"middle\" x=\"86.5\" y=\"-1055.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 140413837835792&#45;&gt;140413837832824 -->\n<g id=\"edge20\" class=\"edge\">\n<title>140413837835792&#45;&gt;140413837832824</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M106.4179,-1048.3715C125.553,-1038.1608 154.6839,-1022.6162 176.4131,-1011.0212\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"178.3423,-1013.9589 185.5171,-1006.1631 175.0468,-1007.7831 178.3423,-1013.9589\"/>\n</g>\n<!-- 140413837874624 -->\n<g id=\"node22\" class=\"node\">\n<title>140413837874624</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"165,-1133 8,-1133 8,-1112 165,-1112 165,-1133\"/>\n<text text-anchor=\"middle\" x=\"86.5\" y=\"-1119.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n</g>\n<!-- 140413837874624&#45;&gt;140413837835792 -->\n<g id=\"edge21\" class=\"edge\">\n<title>140413837874624&#45;&gt;140413837835792</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M86.5,-1111.7281C86.5,-1103.0091 86.5,-1090.4699 86.5,-1079.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"90.0001,-1079.6128 86.5,-1069.6128 83.0001,-1079.6129 90.0001,-1079.6128\"/>\n</g>\n<!-- 140413837874792 -->\n<g id=\"node23\" class=\"node\">\n<title>140413837874792</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"81,-1203 0,-1203 0,-1169 81,-1169 81,-1203\"/>\n<text text-anchor=\"middle\" x=\"40.5\" y=\"-1189.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv1.weight</text>\n<text text-anchor=\"middle\" x=\"40.5\" y=\"-1176.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16, 1, 3, 3)</text>\n</g>\n<!-- 140413837874792&#45;&gt;140413837874624 -->\n<g id=\"edge22\" class=\"edge\">\n<title>140413837874792&#45;&gt;140413837874624</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M52.8272,-1168.9832C58.9107,-1160.5853 66.2742,-1150.4204 72.5621,-1141.7404\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.5945,-1143.5204 78.6266,-1133.3687 69.9256,-1139.4138 75.5945,-1143.5204\"/>\n</g>\n<!-- 140413837877144 -->\n<g id=\"node24\" class=\"node\">\n<title>140413837877144</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"167.5,-1203 99.5,-1203 99.5,-1169 167.5,-1169 167.5,-1203\"/>\n<text text-anchor=\"middle\" x=\"133.5\" y=\"-1189.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv1.bias</text>\n<text text-anchor=\"middle\" x=\"133.5\" y=\"-1176.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16)</text>\n</g>\n<!-- 140413837877144&#45;&gt;140413837874624 -->\n<g id=\"edge23\" class=\"edge\">\n<title>140413837877144&#45;&gt;140413837874624</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M120.9049,-1168.9832C114.6237,-1160.4969 107.0069,-1150.2062 100.5384,-1141.4668\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"103.3071,-1139.3243 94.5445,-1133.3687 97.6806,-1143.4888 103.3071,-1139.3243\"/>\n</g>\n<!-- 140413837833160 -->\n<g id=\"node25\" class=\"node\">\n<title>140413837833160</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"259.5,-1076 151.5,-1076 151.5,-1042 259.5,-1042 259.5,-1076\"/>\n<text text-anchor=\"middle\" x=\"205.5\" y=\"-1062.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">batchnorm1.weight</text>\n<text text-anchor=\"middle\" x=\"205.5\" y=\"-1049.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16)</text>\n</g>\n<!-- 140413837833160&#45;&gt;140413837832824 -->\n<g id=\"edge24\" class=\"edge\">\n<title>140413837833160&#45;&gt;140413837832824</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M205.5,-1041.9832C205.5,-1034.1157 205.5,-1024.6973 205.5,-1016.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"209.0001,-1016.3686 205.5,-1006.3687 202.0001,-1016.3687 209.0001,-1016.3686\"/>\n</g>\n<!-- 140413837877088 -->\n<g id=\"node26\" class=\"node\">\n<title>140413837877088</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"373,-1076 278,-1076 278,-1042 373,-1042 373,-1076\"/>\n<text text-anchor=\"middle\" x=\"325.5\" y=\"-1062.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">batchnorm1.bias</text>\n<text text-anchor=\"middle\" x=\"325.5\" y=\"-1049.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16)</text>\n</g>\n<!-- 140413837877088&#45;&gt;140413837832824 -->\n<g id=\"edge25\" class=\"edge\">\n<title>140413837877088&#45;&gt;140413837832824</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M293.3422,-1041.9832C275.1833,-1032.3741 252.6526,-1020.4516 234.9561,-1011.0872\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"236.1563,-1007.7625 225.6804,-1006.1788 232.8822,-1013.9496 236.1563,-1007.7625\"/>\n</g>\n<!-- 140413837832600 -->\n<g id=\"node27\" class=\"node\">\n<title>140413837832600</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"395,-949 314,-949 314,-915 395,-915 395,-949\"/>\n<text text-anchor=\"middle\" x=\"354.5\" y=\"-935.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv2.weight</text>\n<text text-anchor=\"middle\" x=\"354.5\" y=\"-922.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32, 16, 3, 3)</text>\n</g>\n<!-- 140413837832600&#45;&gt;140413837835736 -->\n<g id=\"edge26\" class=\"edge\">\n<title>140413837832600&#45;&gt;140413837835736</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M354.5,-914.9832C354.5,-907.1157 354.5,-897.6973 354.5,-889.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"358.0001,-889.3686 354.5,-879.3687 351.0001,-889.3687 358.0001,-889.3686\"/>\n</g>\n<!-- 140413837834112 -->\n<g id=\"node28\" class=\"node\">\n<title>140413837834112</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"481.5,-949 413.5,-949 413.5,-915 481.5,-915 481.5,-949\"/>\n<text text-anchor=\"middle\" x=\"447.5\" y=\"-935.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv2.bias</text>\n<text text-anchor=\"middle\" x=\"447.5\" y=\"-922.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32)</text>\n</g>\n<!-- 140413837834112&#45;&gt;140413837835736 -->\n<g id=\"edge27\" class=\"edge\">\n<title>140413837834112&#45;&gt;140413837835736</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M422.5777,-914.9832C408.8955,-905.641 392.0107,-894.1122 378.4799,-884.8734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"380.372,-881.9273 370.1398,-879.1788 376.4248,-887.7082 380.372,-881.9273\"/>\n</g>\n<!-- 140413837832936 -->\n<g id=\"node29\" class=\"node\">\n<title>140413837832936</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"527.5,-822 419.5,-822 419.5,-788 527.5,-788 527.5,-822\"/>\n<text text-anchor=\"middle\" x=\"473.5\" y=\"-808.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">batchnorm2.weight</text>\n<text text-anchor=\"middle\" x=\"473.5\" y=\"-795.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32)</text>\n</g>\n<!-- 140413837832936&#45;&gt;140413837834224 -->\n<g id=\"edge28\" class=\"edge\">\n<title>140413837832936&#45;&gt;140413837834224</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M473.5,-787.9832C473.5,-780.1157 473.5,-770.6973 473.5,-762.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"477.0001,-762.3686 473.5,-752.3687 470.0001,-762.3687 477.0001,-762.3686\"/>\n</g>\n<!-- 140413837833776 -->\n<g id=\"node30\" class=\"node\">\n<title>140413837833776</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"641,-822 546,-822 546,-788 641,-788 641,-822\"/>\n<text text-anchor=\"middle\" x=\"593.5\" y=\"-808.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">batchnorm2.bias</text>\n<text text-anchor=\"middle\" x=\"593.5\" y=\"-795.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32)</text>\n</g>\n<!-- 140413837833776&#45;&gt;140413837834224 -->\n<g id=\"edge29\" class=\"edge\">\n<title>140413837833776&#45;&gt;140413837834224</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M561.3422,-787.9832C543.1833,-778.3741 520.6526,-766.4516 502.9561,-757.0872\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"504.1563,-753.7625 493.6804,-752.1788 500.8822,-759.9496 504.1563,-753.7625\"/>\n</g>\n<!-- 140413838250616 -->\n<g id=\"node31\" class=\"node\">\n<title>140413838250616</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"612,-561.5 539,-561.5 539,-540.5 612,-540.5 612,-561.5\"/>\n<text text-anchor=\"middle\" x=\"575.5\" y=\"-547.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 140413838250616&#45;&gt;140413838251344 -->\n<g id=\"edge30\" class=\"edge\">\n<title>140413838250616&#45;&gt;140413838251344</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M560.1603,-540.3685C543.6024,-528.8927 517.033,-510.4783 497.8726,-497.1988\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"499.8659,-494.3219 489.6532,-491.5022 495.8784,-500.0752 499.8659,-494.3219\"/>\n</g>\n<!-- 140413838253136 -->\n<g id=\"node32\" class=\"node\">\n<title>140413838253136</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"614,-638 539,-638 539,-604 614,-604 614,-638\"/>\n<text text-anchor=\"middle\" x=\"576.5\" y=\"-624.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc1.weight</text>\n<text text-anchor=\"middle\" x=\"576.5\" y=\"-611.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (256, 1568)</text>\n</g>\n<!-- 140413838253136&#45;&gt;140413838250616 -->\n<g id=\"edge31\" class=\"edge\">\n<title>140413838253136&#45;&gt;140413838250616</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M576.2528,-603.6966C576.1152,-594.0634 575.9429,-582.003 575.7979,-571.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"579.2967,-571.7402 575.6542,-561.7913 572.2975,-571.8403 579.2967,-571.7402\"/>\n</g>\n<!-- 140413838250336 -->\n<g id=\"node33\" class=\"node\">\n<title>140413838250336</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"615,-421.5 542,-421.5 542,-400.5 615,-400.5 615,-421.5\"/>\n<text text-anchor=\"middle\" x=\"578.5\" y=\"-407.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 140413838250336&#45;&gt;140413838250392 -->\n<g id=\"edge32\" class=\"edge\">\n<title>140413838250336&#45;&gt;140413838250392</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M562.8565,-400.3685C545.9707,-388.8927 518.8752,-370.4783 499.3354,-357.1988\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"501.1913,-354.2284 490.9532,-351.5022 497.2567,-360.0179 501.1913,-354.2284\"/>\n</g>\n<!-- 140413838251568 -->\n<g id=\"node34\" class=\"node\">\n<title>140413838251568</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"614,-498 545,-498 545,-464 614,-464 614,-498\"/>\n<text text-anchor=\"middle\" x=\"579.5\" y=\"-484.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc2.weight</text>\n<text text-anchor=\"middle\" x=\"579.5\" y=\"-471.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (128, 256)</text>\n</g>\n<!-- 140413838251568&#45;&gt;140413838250336 -->\n<g id=\"edge33\" class=\"edge\">\n<title>140413838251568&#45;&gt;140413838250336</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M579.2528,-463.6966C579.1152,-454.0634 578.9429,-442.003 578.7979,-431.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"582.2967,-431.7402 578.6542,-421.7913 575.2975,-431.8403 582.2967,-431.7402\"/>\n</g>\n<!-- 140413838250448 -->\n<g id=\"node35\" class=\"node\">\n<title>140413838250448</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"615,-281.5 542,-281.5 542,-260.5 615,-260.5 615,-281.5\"/>\n<text text-anchor=\"middle\" x=\"578.5\" y=\"-267.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 140413838250448&#45;&gt;140413872347680 -->\n<g id=\"edge34\" class=\"edge\">\n<title>140413838250448&#45;&gt;140413872347680</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M562.8565,-260.3685C545.9707,-248.8927 518.8752,-230.4783 499.3354,-217.1988\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"501.1913,-214.2284 490.9532,-211.5022 497.2567,-220.0179 501.1913,-214.2284\"/>\n</g>\n<!-- 140413838250112 -->\n<g id=\"node36\" class=\"node\">\n<title>140413838250112</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"613,-358 546,-358 546,-324 613,-324 613,-358\"/>\n<text text-anchor=\"middle\" x=\"579.5\" y=\"-344.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc4.weight</text>\n<text text-anchor=\"middle\" x=\"579.5\" y=\"-331.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64, 128)</text>\n</g>\n<!-- 140413838250112&#45;&gt;140413838250448 -->\n<g id=\"edge35\" class=\"edge\">\n<title>140413838250112&#45;&gt;140413838250448</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M579.2528,-323.6966C579.1152,-314.0634 578.9429,-302.003 578.7979,-291.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"582.2967,-291.7402 578.6542,-281.7913 575.2975,-291.8403 582.2967,-291.7402\"/>\n</g>\n<!-- 140413872346896 -->\n<g id=\"node37\" class=\"node\">\n<title>140413872346896</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"616,-141.5 543,-141.5 543,-120.5 616,-120.5 616,-141.5\"/>\n<text text-anchor=\"middle\" x=\"579.5\" y=\"-127.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 140413872346896&#45;&gt;140413872346392 -->\n<g id=\"edge36\" class=\"edge\">\n<title>140413872346896&#45;&gt;140413872346392</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M562.0275,-120.2281C545.6519,-110.1325 520.9682,-94.9149 502.3209,-83.4187\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"504.0636,-80.3814 493.7145,-78.1128 500.3901,-86.3401 504.0636,-80.3814\"/>\n</g>\n<!-- 140413872346504 -->\n<g id=\"node38\" class=\"node\">\n<title>140413872346504</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"613,-218 546,-218 546,-184 613,-184 613,-218\"/>\n<text text-anchor=\"middle\" x=\"579.5\" y=\"-204.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc3.weight</text>\n<text text-anchor=\"middle\" x=\"579.5\" y=\"-191.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (6, 64)</text>\n</g>\n<!-- 140413872346504&#45;&gt;140413872346896 -->\n<g id=\"edge37\" class=\"edge\">\n<title>140413872346504&#45;&gt;140413872346896</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M579.5,-183.6966C579.5,-174.0634 579.5,-162.003 579.5,-151.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"583.0001,-151.7912 579.5,-141.7913 576.0001,-151.7913 583.0001,-151.7912\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_9CTlb4Yx7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define training parameters\n",
        "batch_size = 32\n",
        "learning_rate = 1e-2\n",
        "n_epochs = 5\n",
        "# Get our data into the mini batch size that we defined\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, sampler=train_sampler, num_workers = 2)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 128, sampler=test_sampler, num_workers = 2)\n",
        "\n",
        "def train_model(net):\n",
        "    \"\"\" Train a the specified network.\n",
        "\n",
        "        Outputs a tuple with the following four elements\n",
        "        train_hist_x: the x-values (batch number) that the training set was \n",
        "            evaluated on.\n",
        "        train_loss_hist: the loss values for the training set corresponding to\n",
        "            the batch numbers returned in train_hist_x\n",
        "        test_hist_x: the x-values (batch number) that the test set was \n",
        "            evaluated on.\n",
        "        test_loss_hist: the loss values for the test set corresponding to\n",
        "            the batch numbers returned in test_hist_x\n",
        "    \"\"\" \n",
        "    loss, optimizer = net.get_loss(learning_rate)\n",
        "    # Define some parameters to keep track of metrics\n",
        "    print_every = 200\n",
        "    idx = 0\n",
        "    train_hist_x = []\n",
        "    train_loss_hist = []\n",
        "    test_hist_x = []\n",
        "    test_loss_hist = []\n",
        "\n",
        "    training_start_time = time.time()\n",
        "    # Loop for n_epochs\n",
        "    for epoch in range(n_epochs):\n",
        "        running_loss = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "            # Get inputs in right form\n",
        "            inputs, labels = data\n",
        "            inputs, labels = Variable(inputs).to(device), Variable(labels).to(device)\n",
        "            \n",
        "            # In Pytorch, We need to always remember to set the optimizer gradients to 0 before we recompute the new gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = net(inputs)\n",
        "            \n",
        "            # Compute the loss and find the loss with respect to each parameter of the model\n",
        "            loss_size = loss(outputs, labels)\n",
        "            loss_size.backward()\n",
        "            \n",
        "            # Change each parameter with respect to the recently computed loss.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update statistics\n",
        "            running_loss += loss_size.data.item()\n",
        "            \n",
        "            # Print every 20th batch of an epoch\n",
        "            if (i % print_every) == print_every-1:\n",
        "                print(\"Epoch {}, Iteration {}\\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
        "                    epoch + 1, i+1,running_loss / print_every, time.time() - start_time))\n",
        "                # Reset running loss and time\n",
        "                train_loss_hist.append(running_loss / print_every)\n",
        "                train_hist_x.append(idx)\n",
        "                running_loss = 0.0\n",
        "                start_time = time.time()\n",
        "            idx += 1\n",
        "\n",
        "        # At the end of the epoch, do a pass on the test set\n",
        "        total_test_loss = 0\n",
        "        for inputs, labels in test_loader:\n",
        "\n",
        "            # Wrap tensors in Variables\n",
        "            inputs, labels = Variable(inputs).to(device), Variable(labels).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            test_outputs = net(inputs)\n",
        "            test_loss_size = loss(test_outputs, labels)\n",
        "            total_test_loss += test_loss_size.data.item()\n",
        "        test_loss_hist.append(total_test_loss / len(test_loader))\n",
        "        test_hist_x.append(idx)\n",
        "        print(\"Validation loss = {:.2f}\".format(\n",
        "            total_test_loss / len(test_loader)))\n",
        "\n",
        "    print(\"Training finished, took {:.2f}s\".format(\n",
        "        time.time() - training_start_time))\n",
        "    return train_hist_x, train_loss_hist, test_hist_x, test_loss_hist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGyZdjgNjf_h",
        "colab_type": "code",
        "outputId": "af36c3eb-a538-4cc3-9c3b-55e4254f317e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_hist_x, train_loss_hist, test_hist_x, test_loss_hist = train_model(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:78: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Iteration 200\t train_loss: 0.74 took: 1.95s\n",
            "Epoch 1, Iteration 400\t train_loss: 0.50 took: 1.80s\n",
            "Epoch 1, Iteration 600\t train_loss: 0.47 took: 1.76s\n",
            "Epoch 1, Iteration 800\t train_loss: 0.45 took: 1.79s\n",
            "Epoch 1, Iteration 1000\t train_loss: 0.42 took: 1.79s\n",
            "Epoch 1, Iteration 1200\t train_loss: 0.40 took: 1.76s\n",
            "Epoch 1, Iteration 1400\t train_loss: 0.39 took: 1.76s\n",
            "Epoch 1, Iteration 1600\t train_loss: 0.37 took: 1.79s\n",
            "Epoch 1, Iteration 1800\t train_loss: 0.35 took: 1.78s\n",
            "Epoch 1, Iteration 2000\t train_loss: 0.35 took: 1.78s\n",
            "Epoch 1, Iteration 2200\t train_loss: 0.36 took: 1.78s\n",
            "Epoch 1, Iteration 2400\t train_loss: 0.34 took: 1.78s\n",
            "Epoch 1, Iteration 2600\t train_loss: 0.34 took: 1.78s\n",
            "Epoch 1, Iteration 2800\t train_loss: 0.32 took: 1.76s\n",
            "Epoch 1, Iteration 3000\t train_loss: 0.36 took: 1.77s\n",
            "Epoch 1, Iteration 3200\t train_loss: 0.33 took: 1.78s\n",
            "Epoch 1, Iteration 3400\t train_loss: 0.35 took: 1.79s\n",
            "Epoch 1, Iteration 3600\t train_loss: 0.33 took: 1.78s\n",
            "Epoch 1, Iteration 3800\t train_loss: 0.33 took: 1.77s\n",
            "Epoch 1, Iteration 4000\t train_loss: 0.31 took: 1.79s\n",
            "Epoch 1, Iteration 4200\t train_loss: 0.32 took: 1.77s\n",
            "Epoch 1, Iteration 4400\t train_loss: 0.33 took: 1.78s\n",
            "Epoch 1, Iteration 4600\t train_loss: 0.34 took: 1.80s\n",
            "Epoch 1, Iteration 4800\t train_loss: 0.34 took: 1.77s\n",
            "Epoch 1, Iteration 5000\t train_loss: 0.34 took: 1.78s\n",
            "Epoch 1, Iteration 5200\t train_loss: 0.33 took: 1.76s\n",
            "Epoch 1, Iteration 5400\t train_loss: 0.34 took: 1.78s\n",
            "Epoch 1, Iteration 5600\t train_loss: 0.33 took: 1.75s\n",
            "Epoch 1, Iteration 5800\t train_loss: 0.32 took: 1.77s\n",
            "Epoch 1, Iteration 6000\t train_loss: 0.32 took: 1.79s\n",
            "Epoch 1, Iteration 6200\t train_loss: 0.33 took: 1.76s\n",
            "Epoch 1, Iteration 6400\t train_loss: 0.31 took: 1.77s\n",
            "Epoch 1, Iteration 6600\t train_loss: 0.31 took: 1.80s\n",
            "Epoch 1, Iteration 6800\t train_loss: 0.30 took: 1.82s\n",
            "Epoch 1, Iteration 7000\t train_loss: 0.31 took: 1.79s\n",
            "Epoch 1, Iteration 7200\t train_loss: 0.32 took: 1.75s\n",
            "Epoch 1, Iteration 7400\t train_loss: 0.33 took: 1.77s\n",
            "Epoch 1, Iteration 7600\t train_loss: 0.30 took: 1.80s\n",
            "Epoch 1, Iteration 7800\t train_loss: 0.31 took: 1.84s\n",
            "Epoch 1, Iteration 8000\t train_loss: 0.29 took: 1.80s\n",
            "Epoch 1, Iteration 8200\t train_loss: 0.31 took: 1.86s\n",
            "Epoch 1, Iteration 8400\t train_loss: 0.29 took: 1.81s\n",
            "Epoch 1, Iteration 8600\t train_loss: 0.32 took: 1.82s\n",
            "Epoch 1, Iteration 8800\t train_loss: 0.31 took: 1.78s\n",
            "Epoch 1, Iteration 9000\t train_loss: 0.31 took: 1.76s\n",
            "Epoch 1, Iteration 9200\t train_loss: 0.32 took: 1.77s\n",
            "Epoch 1, Iteration 9400\t train_loss: 0.29 took: 1.77s\n",
            "Epoch 1, Iteration 9600\t train_loss: 0.30 took: 1.75s\n",
            "Epoch 1, Iteration 9800\t train_loss: 0.29 took: 1.77s\n",
            "Epoch 1, Iteration 10000\t train_loss: 0.31 took: 1.79s\n",
            "Epoch 1, Iteration 10200\t train_loss: 0.31 took: 1.78s\n",
            "Epoch 1, Iteration 10400\t train_loss: 0.30 took: 1.78s\n",
            "Epoch 1, Iteration 10600\t train_loss: 0.28 took: 1.78s\n",
            "Epoch 1, Iteration 10800\t train_loss: 0.31 took: 1.78s\n",
            "Epoch 1, Iteration 11000\t train_loss: 0.31 took: 1.75s\n",
            "Epoch 1, Iteration 11200\t train_loss: 0.29 took: 1.77s\n",
            "Epoch 1, Iteration 11400\t train_loss: 0.29 took: 1.75s\n",
            "Epoch 1, Iteration 11600\t train_loss: 0.29 took: 1.76s\n",
            "Epoch 1, Iteration 11800\t train_loss: 0.30 took: 1.78s\n",
            "Epoch 1, Iteration 12000\t train_loss: 0.28 took: 1.77s\n",
            "Epoch 1, Iteration 12200\t train_loss: 0.30 took: 1.79s\n",
            "Epoch 1, Iteration 12400\t train_loss: 0.30 took: 1.75s\n",
            "Epoch 1, Iteration 12600\t train_loss: 0.30 took: 1.77s\n",
            "Epoch 1, Iteration 12800\t train_loss: 0.31 took: 1.78s\n",
            "Epoch 1, Iteration 13000\t train_loss: 0.29 took: 1.78s\n",
            "Epoch 1, Iteration 13200\t train_loss: 0.29 took: 1.76s\n",
            "Epoch 1, Iteration 13400\t train_loss: 0.28 took: 1.79s\n",
            "Epoch 1, Iteration 13600\t train_loss: 0.31 took: 1.77s\n",
            "Epoch 1, Iteration 13800\t train_loss: 0.29 took: 1.75s\n",
            "Epoch 1, Iteration 14000\t train_loss: 0.28 took: 1.77s\n",
            "Epoch 1, Iteration 14200\t train_loss: 0.27 took: 1.78s\n",
            "Epoch 1, Iteration 14400\t train_loss: 0.31 took: 1.77s\n",
            "Epoch 1, Iteration 14600\t train_loss: 0.32 took: 1.77s\n",
            "Epoch 1, Iteration 14800\t train_loss: 0.28 took: 1.78s\n",
            "Epoch 1, Iteration 15000\t train_loss: 0.31 took: 1.78s\n",
            "Epoch 1, Iteration 15200\t train_loss: 0.29 took: 1.75s\n",
            "Epoch 1, Iteration 15400\t train_loss: 0.30 took: 1.77s\n",
            "Epoch 1, Iteration 15600\t train_loss: 0.27 took: 1.78s\n",
            "Epoch 1, Iteration 15800\t train_loss: 0.29 took: 1.74s\n",
            "Epoch 1, Iteration 16000\t train_loss: 0.29 took: 1.75s\n",
            "Epoch 1, Iteration 16200\t train_loss: 0.29 took: 1.76s\n",
            "Epoch 1, Iteration 16400\t train_loss: 0.28 took: 1.75s\n",
            "Epoch 1, Iteration 16600\t train_loss: 0.29 took: 1.76s\n",
            "Epoch 1, Iteration 16800\t train_loss: 0.30 took: 1.75s\n",
            "Epoch 1, Iteration 17000\t train_loss: 0.28 took: 1.78s\n",
            "Epoch 1, Iteration 17200\t train_loss: 0.29 took: 1.77s\n",
            "Epoch 1, Iteration 17400\t train_loss: 0.29 took: 1.77s\n",
            "Epoch 1, Iteration 17600\t train_loss: 0.29 took: 1.79s\n",
            "Epoch 1, Iteration 17800\t train_loss: 0.27 took: 1.76s\n",
            "Epoch 1, Iteration 18000\t train_loss: 0.28 took: 1.76s\n",
            "Epoch 1, Iteration 18200\t train_loss: 0.31 took: 1.75s\n",
            "Epoch 1, Iteration 18400\t train_loss: 0.29 took: 1.75s\n",
            "Epoch 1, Iteration 18600\t train_loss: 0.29 took: 1.78s\n",
            "Epoch 1, Iteration 18800\t train_loss: 0.28 took: 1.76s\n",
            "Epoch 1, Iteration 19000\t train_loss: 0.28 took: 1.80s\n",
            "Epoch 1, Iteration 19200\t train_loss: 0.29 took: 1.81s\n",
            "Epoch 1, Iteration 19400\t train_loss: 0.30 took: 1.79s\n",
            "Epoch 1, Iteration 19600\t train_loss: 0.28 took: 1.78s\n",
            "Epoch 1, Iteration 19800\t train_loss: 0.28 took: 1.76s\n",
            "Epoch 1, Iteration 20000\t train_loss: 0.28 took: 1.78s\n",
            "Epoch 1, Iteration 20200\t train_loss: 0.29 took: 1.77s\n",
            "Epoch 1, Iteration 20400\t train_loss: 0.34 took: 1.77s\n",
            "Epoch 1, Iteration 20600\t train_loss: 0.30 took: 1.77s\n",
            "Epoch 1, Iteration 20800\t train_loss: 0.29 took: 1.76s\n",
            "Epoch 1, Iteration 21000\t train_loss: 0.26 took: 1.77s\n",
            "Epoch 1, Iteration 21200\t train_loss: 0.28 took: 1.78s\n",
            "Epoch 1, Iteration 21400\t train_loss: 0.29 took: 1.78s\n",
            "Epoch 1, Iteration 21600\t train_loss: 0.28 took: 1.75s\n",
            "Epoch 1, Iteration 21800\t train_loss: 0.28 took: 1.74s\n",
            "Epoch 1, Iteration 22000\t train_loss: 0.28 took: 1.79s\n",
            "Epoch 1, Iteration 22200\t train_loss: 0.28 took: 1.76s\n",
            "Epoch 1, Iteration 22400\t train_loss: 0.30 took: 1.79s\n",
            "Epoch 1, Iteration 22600\t train_loss: 0.30 took: 1.78s\n",
            "Epoch 1, Iteration 22800\t train_loss: 0.28 took: 1.77s\n",
            "Epoch 1, Iteration 23000\t train_loss: 0.29 took: 1.77s\n",
            "Validation loss = 0.27\n",
            "Epoch 2, Iteration 200\t train_loss: 0.29 took: 1.91s\n",
            "Epoch 2, Iteration 400\t train_loss: 0.28 took: 1.83s\n",
            "Epoch 2, Iteration 600\t train_loss: 0.29 took: 1.77s\n",
            "Epoch 2, Iteration 800\t train_loss: 0.28 took: 1.81s\n",
            "Epoch 2, Iteration 1000\t train_loss: 0.32 took: 1.81s\n",
            "Epoch 2, Iteration 1200\t train_loss: 0.30 took: 1.81s\n",
            "Epoch 2, Iteration 1400\t train_loss: 0.29 took: 1.81s\n",
            "Epoch 2, Iteration 1600\t train_loss: 0.27 took: 1.80s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVNSsFzVji6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(train_hist_x,train_loss_hist)\n",
        "plt.plot(test_hist_x,test_loss_hist)\n",
        "plt.legend(['train loss', 'validation loss'])\n",
        "plt.xlabel('Batch number')\n",
        "plt.ylabel('Loss')\n",
        "# plt.xlim(0,12000)\n",
        "# plt.ylim(0,2)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ13LfcF3Ji2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(net, loader):\n",
        "    n_correct = 0\n",
        "    n_total = 0\n",
        "    for i, data in enumerate(loader, 0):\n",
        "        # Get inputs in right form\n",
        "        inputs, labels = data\n",
        "        inputs, labels = Variable(inputs).to(device), Variable(labels).to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = net(inputs)\n",
        "        n_correct += np.sum(np.argmax(outputs.cpu().detach().numpy(), axis=1) == labels.cpu().numpy())\n",
        "        n_total += labels.shape[0]\n",
        "    return n_correct/n_total\n",
        "print(\"Train accuracy is\", get_accuracy(net, train_loader))\n",
        "print(\"Test accuracy is\", get_accuracy(net, test_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqMZxrWj47rA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def examine_label(idx):\n",
        "    image, label = test_set[idx]\n",
        "    class_scores = net(Variable(image.unsqueeze(0)).to(device))\n",
        "    prediction = np.argmax(class_scores.cpu().detach().numpy())\n",
        "    confidence = class_scores.cpu().detach().numpy()\n",
        "    plt.imshow(image.squeeze(), cmap='gray')\n",
        "    plt.show()\n",
        "    print(prediction)\n",
        "    print(label)\n",
        "    print(max(confidence[0])/sum(confidence[0]))\n",
        "    print(confidence)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSeuwv8R5NGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}